{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ram58059/CICD-jenkins-Sonarqube/blob/main/yoga_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHKdiHIq-8XJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from PIL import Image\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.applications import VGG16, InceptionResNetV2\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ct-4xUym_JnV"
      },
      "outputs": [],
      "source": [
        "train_dir = 'drive/MyDrive/DATASET/TRAIN'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYBI8BmF_dmO"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(width_shift_range= 0.1,\n",
        "                                  horizontal_flip = True,\n",
        "                                  rescale = 1./255,\n",
        "                                  validation_split = 0.2,)\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  validation_split = 0.2,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCpvj1nT_iAl",
        "outputId": "211173f2-9482-4290-c6c6-ef586808d0ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 882 images belonging to 5 classes.\n",
            "Found 219 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator =  train_datagen.flow_from_directory(directory = train_dir,\n",
        "                                                    target_size = (224,224),\n",
        "                                                    color_mode = 'rgb',\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    batch_size = 16,\n",
        "                                                    shuffle=True,\n",
        "                                                    subset = 'training')\n",
        "validation_generator  = validation_datagen.flow_from_directory(directory = train_dir,\n",
        "                                                  target_size = (224,224),\n",
        "                                                  color_mode = 'rgb',\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  shuffle=False,\n",
        "                                                  subset = 'validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-Pju4sq_iN8",
        "outputId": "f22faa13-95bb-40aa-ada6-431d8b2ecfc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgEE-N1S_iQ7"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding = 'Same', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    #tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\n",
        "    #tf.keras.layers.MaxPooling2D(2,2),\n",
        "    #tf.keras.layers.Dropout(0.25),\n",
        "    #tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\n",
        "    #tf.keras.layers.MaxPooling2D(2,2),\n",
        "    #tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu',padding = 'Same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu',padding = 'Same'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQfkS6HO_iUZ",
        "outputId": "e5914d22-2f5f-45a2-ef86-5e9081f71143"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "optimizer = Adam(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = optimizer,\n",
        "              metrics=['accuracy'])\n",
        "epochs = 50\n",
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceLpEB6e_uCt",
        "outputId": "c13c1e9b-e2a7-4154-e79d-8a5384db554f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 200704)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              205521920 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 5125      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 205,897,861\n",
            "Trainable params: 205,897,861\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z0yqoAQ_wHs"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPqbtB3R_yld",
        "outputId": "93fa46f2-62d8-4b46-ee9c-9f2d150c4711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "18/56 [========>.....................] - ETA: 2:10 - loss: 10.9801 - accuracy: 0.2431"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/PIL/Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "56/56 [==============================] - 236s 4s/step - loss: 4.6649 - accuracy: 0.2426 - val_loss: 1.6037 - val_accuracy: 0.2420\n",
            "Epoch 2/50\n",
            "56/56 [==============================] - 30s 535ms/step - loss: 1.5967 - accuracy: 0.2392 - val_loss: 1.5869 - val_accuracy: 0.2374\n",
            "Epoch 3/50\n",
            "56/56 [==============================] - 31s 547ms/step - loss: 1.5638 - accuracy: 0.2993 - val_loss: 1.4364 - val_accuracy: 0.4155\n",
            "Epoch 4/50\n",
            "56/56 [==============================] - 29s 520ms/step - loss: 1.4155 - accuracy: 0.4331 - val_loss: 1.2122 - val_accuracy: 0.5388\n",
            "Epoch 5/50\n",
            "56/56 [==============================] - 30s 541ms/step - loss: 1.2733 - accuracy: 0.5227 - val_loss: 1.0215 - val_accuracy: 0.6256\n",
            "Epoch 6/50\n",
            "56/56 [==============================] - 29s 522ms/step - loss: 1.1395 - accuracy: 0.5714 - val_loss: 0.9584 - val_accuracy: 0.6073\n",
            "Epoch 7/50\n",
            "56/56 [==============================] - 29s 522ms/step - loss: 1.0699 - accuracy: 0.6190 - val_loss: 0.9422 - val_accuracy: 0.6438\n",
            "Epoch 8/50\n",
            "56/56 [==============================] - 29s 521ms/step - loss: 1.0209 - accuracy: 0.6270 - val_loss: 0.8293 - val_accuracy: 0.7123\n",
            "Epoch 9/50\n",
            "56/56 [==============================] - 29s 513ms/step - loss: 0.8732 - accuracy: 0.6848 - val_loss: 0.7911 - val_accuracy: 0.7123\n",
            "Epoch 10/50\n",
            "56/56 [==============================] - 30s 538ms/step - loss: 0.8048 - accuracy: 0.7256 - val_loss: 0.7232 - val_accuracy: 0.7352\n",
            "Epoch 11/50\n",
            "56/56 [==============================] - 29s 511ms/step - loss: 0.7408 - accuracy: 0.7302 - val_loss: 0.7491 - val_accuracy: 0.7260\n",
            "Epoch 12/50\n",
            "56/56 [==============================] - 29s 521ms/step - loss: 0.7179 - accuracy: 0.7732 - val_loss: 0.7420 - val_accuracy: 0.7215\n",
            "Epoch 13/50\n",
            "56/56 [==============================] - 30s 532ms/step - loss: 0.6225 - accuracy: 0.7823 - val_loss: 0.7455 - val_accuracy: 0.7352\n",
            "Epoch 14/50\n",
            "56/56 [==============================] - 29s 512ms/step - loss: 0.5854 - accuracy: 0.7937 - val_loss: 0.7325 - val_accuracy: 0.7626\n",
            "Epoch 15/50\n",
            "56/56 [==============================] - 31s 552ms/step - loss: 0.5278 - accuracy: 0.8311 - val_loss: 0.7559 - val_accuracy: 0.7626\n",
            "Epoch 16/50\n",
            "56/56 [==============================] - 29s 513ms/step - loss: 0.5244 - accuracy: 0.8322 - val_loss: 0.7213 - val_accuracy: 0.7763\n",
            "Epoch 17/50\n",
            "56/56 [==============================] - 29s 515ms/step - loss: 0.4417 - accuracy: 0.8537 - val_loss: 0.7716 - val_accuracy: 0.7534\n",
            "Epoch 18/50\n",
            "56/56 [==============================] - 29s 509ms/step - loss: 0.4239 - accuracy: 0.8515 - val_loss: 0.7333 - val_accuracy: 0.7763\n",
            "Epoch 19/50\n",
            "56/56 [==============================] - 29s 515ms/step - loss: 0.4298 - accuracy: 0.8571 - val_loss: 0.6951 - val_accuracy: 0.7626\n",
            "Epoch 20/50\n",
            "56/56 [==============================] - 30s 535ms/step - loss: 0.3648 - accuracy: 0.8741 - val_loss: 0.6960 - val_accuracy: 0.7808\n",
            "Epoch 21/50\n",
            "56/56 [==============================] - 29s 514ms/step - loss: 0.3696 - accuracy: 0.8776 - val_loss: 0.7006 - val_accuracy: 0.7763\n",
            "Epoch 22/50\n",
            "56/56 [==============================] - 29s 525ms/step - loss: 0.3363 - accuracy: 0.8878 - val_loss: 0.7246 - val_accuracy: 0.7900\n",
            "Epoch 23/50\n",
            "56/56 [==============================] - 29s 520ms/step - loss: 0.3290 - accuracy: 0.8844 - val_loss: 0.6729 - val_accuracy: 0.7991\n",
            "Epoch 24/50\n",
            "56/56 [==============================] - 28s 507ms/step - loss: 0.2965 - accuracy: 0.8991 - val_loss: 0.6914 - val_accuracy: 0.7854\n",
            "Epoch 25/50\n",
            "56/56 [==============================] - 29s 508ms/step - loss: 0.2221 - accuracy: 0.9308 - val_loss: 0.7241 - val_accuracy: 0.7991\n",
            "Epoch 26/50\n",
            "56/56 [==============================] - 30s 531ms/step - loss: 0.2345 - accuracy: 0.9161 - val_loss: 0.7703 - val_accuracy: 0.7854\n",
            "Epoch 27/50\n",
            "56/56 [==============================] - 29s 510ms/step - loss: 0.2527 - accuracy: 0.9150 - val_loss: 0.7434 - val_accuracy: 0.7991\n",
            "Epoch 28/50\n",
            "56/56 [==============================] - 28s 508ms/step - loss: 0.2418 - accuracy: 0.9286 - val_loss: 0.6729 - val_accuracy: 0.8311\n",
            "Epoch 29/50\n",
            "56/56 [==============================] - 30s 541ms/step - loss: 0.1407 - accuracy: 0.9501 - val_loss: 0.8173 - val_accuracy: 0.8037\n",
            "Epoch 30/50\n",
            "56/56 [==============================] - 28s 504ms/step - loss: 0.2291 - accuracy: 0.9422 - val_loss: 0.7735 - val_accuracy: 0.7945\n",
            "Epoch 31/50\n",
            "56/56 [==============================] - 29s 522ms/step - loss: 0.1582 - accuracy: 0.9478 - val_loss: 0.8747 - val_accuracy: 0.7534\n",
            "Epoch 32/50\n",
            "56/56 [==============================] - 29s 511ms/step - loss: 0.1846 - accuracy: 0.9376 - val_loss: 0.8379 - val_accuracy: 0.8082\n",
            "Epoch 33/50\n",
            "56/56 [==============================] - 29s 512ms/step - loss: 0.1499 - accuracy: 0.9433 - val_loss: 0.9107 - val_accuracy: 0.7900\n",
            "Epoch 34/50\n",
            "56/56 [==============================] - 28s 507ms/step - loss: 0.1905 - accuracy: 0.9512 - val_loss: 0.7492 - val_accuracy: 0.7900\n",
            "Epoch 35/50\n",
            "56/56 [==============================] - 28s 506ms/step - loss: 0.1705 - accuracy: 0.9569 - val_loss: 0.7471 - val_accuracy: 0.8219\n",
            "Epoch 36/50\n",
            "56/56 [==============================] - 28s 503ms/step - loss: 0.1470 - accuracy: 0.9467 - val_loss: 0.7513 - val_accuracy: 0.8265\n",
            "Epoch 37/50\n",
            "56/56 [==============================] - 30s 532ms/step - loss: 0.1359 - accuracy: 0.9558 - val_loss: 0.8120 - val_accuracy: 0.8219\n",
            "Epoch 38/50\n",
            "56/56 [==============================] - 28s 503ms/step - loss: 0.1807 - accuracy: 0.9342 - val_loss: 0.9450 - val_accuracy: 0.7671\n",
            "Epoch 39/50\n",
            "56/56 [==============================] - 28s 505ms/step - loss: 0.1837 - accuracy: 0.9410 - val_loss: 0.7680 - val_accuracy: 0.7991\n",
            "Epoch 40/50\n",
            "56/56 [==============================] - 28s 503ms/step - loss: 0.1432 - accuracy: 0.9637 - val_loss: 0.8188 - val_accuracy: 0.8082\n",
            "Epoch 41/50\n",
            "56/56 [==============================] - 28s 506ms/step - loss: 0.1098 - accuracy: 0.9671 - val_loss: 0.8675 - val_accuracy: 0.7900\n",
            "Epoch 42/50\n",
            "56/56 [==============================] - 29s 526ms/step - loss: 0.1343 - accuracy: 0.9603 - val_loss: 0.8340 - val_accuracy: 0.7808\n",
            "Epoch 43/50\n",
            "56/56 [==============================] - 29s 508ms/step - loss: 0.1142 - accuracy: 0.9649 - val_loss: 0.6643 - val_accuracy: 0.8356\n",
            "Epoch 44/50\n",
            "56/56 [==============================] - 28s 509ms/step - loss: 0.1634 - accuracy: 0.9546 - val_loss: 0.7710 - val_accuracy: 0.8174\n",
            "Epoch 45/50\n",
            "56/56 [==============================] - 28s 509ms/step - loss: 0.1416 - accuracy: 0.9580 - val_loss: 0.7643 - val_accuracy: 0.7945\n",
            "Epoch 46/50\n",
            "56/56 [==============================] - 28s 499ms/step - loss: 0.1727 - accuracy: 0.9535 - val_loss: 0.7093 - val_accuracy: 0.8082\n",
            "Epoch 47/50\n",
            "56/56 [==============================] - 29s 517ms/step - loss: 0.0910 - accuracy: 0.9660 - val_loss: 0.7065 - val_accuracy: 0.8265\n",
            "Epoch 48/50\n",
            "56/56 [==============================] - 28s 496ms/step - loss: 0.0769 - accuracy: 0.9785 - val_loss: 0.7828 - val_accuracy: 0.8082\n",
            "Epoch 49/50\n",
            "56/56 [==============================] - 28s 499ms/step - loss: 0.1266 - accuracy: 0.9649 - val_loss: 0.7536 - val_accuracy: 0.8128\n",
            "Epoch 50/50\n",
            "56/56 [==============================] - 28s 496ms/step - loss: 0.0963 - accuracy: 0.9694 - val_loss: 0.7073 - val_accuracy: 0.7991\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator, epochs = epochs,validation_data = validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZ3_083aHQzp"
      },
      "outputs": [],
      "source": [
        "model.save('YogaNet_model_1_1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYeI1TMAHWO2"
      },
      "outputs": [],
      "source": [
        "model = load_model('YogaNet_model_1_1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgusP6vrHa6a",
        "outputId": "8e07531a-7334-43e5-a009-5e2c19522bd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 299ms/step\n",
            "tree\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from keras.models import load_model\n",
        "\n",
        "classes_name = ['downdog', 'goddess', 'plank', 'tree', 'warrior2']\n",
        "img = load_img('drive/MyDrive/DATASET/TEST/tree/00000001.jpg', target_size=(224, 224))\n",
        "# img = load_img('bharat.png', target_size=(224, 224))\n",
        "x = img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "img_data = preprocess_input(x)\n",
        "classes = model.predict(img_data)\n",
        "print(classes_name[np.argmax(classes)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LN_1ZvtqPdBY",
        "outputId": "75e42b2f-ced6-4751-f7a2-5221afbd04d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "tree\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "tree\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "tree\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "tree\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "tree\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "tree\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "tree\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "tree\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "warrior2\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "warrior2\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "warrior2\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "goddess\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "goddess\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "goddess\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "warrior2\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "warrior2\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "warrior2\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "warrior2\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "warrior2\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "warrior2\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "downdog\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "downdog\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-112aeb0618cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"frame1.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0;31m#cv.imshow('image', img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame1.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import cv2 as cv\n",
        "import os\n",
        "\n",
        "# Reading Videos\n",
        "# takes in (0,1,2,etc)-for webcam      or      path to video file\n",
        "capture = cv.VideoCapture('warrior_2.mp4')\n",
        "\n",
        "count = 1\n",
        "# we will be using loop and will bbe reading the video frame by frame\n",
        "while True:\n",
        "    # isTrue - to check whether the frame is successfully read or not\n",
        "    isTrue, frame = capture.read()\n",
        "    # cv.imshow(\"Video\", frame)\n",
        "    count = count + 2\n",
        "    if isTrue and count % 26 == 0:\n",
        "      path = \"frame1.jpg\"\n",
        "      cv.imwrite(path, frame)\n",
        "      img = cv.imread(path)\n",
        "      #cv.imshow('image', img)\n",
        "      img = load_img('frame1.jpg', target_size=(224, 224))\n",
        "      x = img_to_array(img)\n",
        "      x = np.expand_dims(x, axis=0)\n",
        "      img_data = preprocess_input(x)\n",
        "      classes = model.predict(img_data)\n",
        "\n",
        "      print(classes_name[np.argmax(classes)])\n",
        "      if classes_name[np.argmax(classes)] == \"warrior2\":\n",
        "        cv.imwrite(f\"warrior2_TEST__{count}.jpg\", frame)\n",
        "\n",
        "\n",
        "\n",
        "    # so for some way to stop the video from playing indefinetely\n",
        "    if cv.waitKey(20) & 0xFF == ord('d'):\n",
        "        # if letter 'd' is pressed then break out of the loop\n",
        "        break\n",
        "\n",
        "capture.release()\n",
        "cv.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}